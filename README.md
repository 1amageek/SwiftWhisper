# ğŸ™ï¸ Whisper.swift

Whisper.swift is a Swift class that leverages WhisperKit for speech recognition and transcription. This class provides functionality for real-time audio input processing, model management, and transcription setting adjustments. âœ¨

## ğŸŒŸ Key Features

1. **Speech Recognition** ğŸ—£ï¸: Recognizes speech in real-time and converts it to text.
2. **Model Management** ğŸ§ : Manages local and remote speech recognition models.
3. **Customizable Settings** âš™ï¸: Allows customization of various parameters such as audio input, model selection, and language settings.
4. **Real-time Processing** âš¡: Continuously processes streaming audio input and converts it to text.
5. **Performance Monitoring** ğŸ“Š: Tracks performance metrics such as processing time and token generation speed.

## ğŸ§© Main Components

- `WhisperKit` ğŸ¯: The core component for speech recognition
- `AudioProcessor` ğŸšï¸: Responsible for processing audio input
- `ModelState` ğŸ”„: Manages the state of the model (unloaded, downloading, loaded, etc.)
- `TranscriptionResult` ğŸ“: Holds the transcription results

## ğŸš€ Usage

1. **Initialization** ğŸ¬:
   ```swift
   let whisper = Whisper()
   ```

2. **Preparing a Model** ğŸ“¥:
   ```swift
   try await whisper.prepare(model: "modelName") { progress in
       print("Preparation progress: \(progress.fractionCompleted * 100)%")
   }
   ```

3. **Listening and Transcribing** ğŸ§:
   ```swift
   for try await message in whisper.listen() {
       print(message.text)
   }
   ```

4. **Stopping Transcription** ğŸ›‘:
   ```swift
   whisper.stopListening()
   ```

5. **Adjusting Settings** ğŸ› ï¸:
   ```swift
   whisper.selectedLanguage = "english"
   ```

## ğŸ”‘ Key Methods

- `prepare(model:progress:)` ğŸ“¥: Prepares the specified model with progress updates
- `listen()` ğŸ™ï¸: Starts listening and returns an AsyncStream of WhisperMessages
- `stopListening()` ğŸ›‘: Stops the listening process
- `fetchModels()` ğŸ”: Fetches available models
- `deleteModel()` ğŸ—‘ï¸: Deletes the selected model

## ğŸ“ Notes

- This class is marked with `@Observable` and `@MainActor`, making it suitable for use with SwiftUI. ğŸ¨
- The accuracy and speed of speech recognition heavily depend on the selected model and settings. ğŸ¯
- For real-time processing, it's crucial to properly adjust buffer size and silence detection thresholds. ğŸ”§

## ğŸ”— Dependencies

- WhisperKit ğŸ§ 
- AVFoundation ğŸµ
- CoreML ğŸ¤–
- Combine ğŸ”—

This class allows for easy integration of advanced speech recognition capabilities into your application. ğŸš€âœ¨

Happy coding! ğŸ’»ğŸ‰
