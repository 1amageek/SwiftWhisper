
# ğŸ™ï¸ Whisper.swift

Whisper.swift is a Swift class that utilizes WhisperKit for speech recognition and transcription. This class provides functionality for real-time audio input processing, model management, and transcription setting adjustments. âœ¨

## ğŸŒŸ Key Features

1. **Speech Recognition** ğŸ—£ï¸: Recognizes speech in real-time and converts it to text.
2. **Model Management** ğŸ§ : Manages local and remote speech recognition models.
3. **Customizable Settings** âš™ï¸: Allows customization of various parameters such as audio input, model selection, and language settings.
4. **Real-time Processing** âš¡: Continuously processes streaming audio input and converts it to text.
5. **Performance Monitoring** ğŸ“Š: Tracks performance metrics such as processing time and token generation speed.

## ğŸ§© Main Components

- `WhisperKit` ğŸ¯: The core component for speech recognition
- `AudioProcessor` ğŸšï¸: Responsible for processing audio input
- `ModelState` ğŸ”„: Manages the state of the model (unloaded, downloading, loaded, etc.)
- `TranscriptionResult` ğŸ“: Holds the transcription results

## ğŸš€ Usage

1. **Initialization** ğŸ¬:
   ```swift
   let whisper = Whisper()
   ```

2. **Loading a Model** ğŸ“¥:
   ```swift
   whisper.loadModel("modelName")
   ```

3. **Starting/Stopping Recording** â¯ï¸:
   ```swift
   whisper.toggleRecording()
   ```

4. **Adjusting Settings** ğŸ› ï¸:
   ```swift
   whisper.selectedLanguage = "english"
   whisper.enableTimestamps = true
   ```

5. **Retrieving Transcription Results** ğŸ“Š:
   ```swift
   let currentText = whisper.currentText
   ```

## ğŸ”‘ Key Methods

- `fetchModels()` ğŸ”: Fetches available models
- `loadModel(_:redownload:)` ğŸ“¥: Loads a specified model
- `startRecording()` ğŸ™ï¸: Starts audio recording
- `stopRecording()` ğŸ›‘: Stops audio recording
- `transcribeAudioSamples(_:)` ğŸ”„: Transcribes audio samples
- `realtimeLoop()` ğŸ”: Initiates the real-time transcription loop

## ğŸ“ Notes

- This class is marked with `@Observable` and `@MainActor`, making it suitable for use with SwiftUI. ğŸ¨
- The accuracy and speed of speech recognition heavily depend on the selected model and settings. ğŸ¯
- For real-time processing, it's crucial to properly adjust buffer size and silence detection thresholds. ğŸ”§

## ğŸ”— Dependencies

- WhisperKit ğŸ§ 
- AVFoundation ğŸµ
- CoreML ğŸ¤–

This class allows for easy integration of advanced speech recognition capabilities into your application. ğŸš€âœ¨

Happy coding! ğŸ’»ğŸ‰
